#version 460
#extension GL_ARB_gpu_shader_int64 : require
#extension GL_ARB_shader_clock : require
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_ray_tracing : require

#include "Heatmap.glsl"
#include "Random.glsl"
#include "RayPayload.glsl"
#include "UniformBufferObject.glsl"

layout(binding = 0, set = 0) uniform accelerationStructureEXT Scene;//光线追踪场景，包括几何体和材质
layout(binding = 1, rgba32f) uniform image2D AccumulationImage;//累积图像
layout(binding = 2, rgba8) uniform image2D OutputImage;//输出图像
layout(binding = 3) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };//相机参数
layout (binding = 10, set = 0, rgba8) uniform image2D saveImage;
layout(binding = 11, set = 0) uniform sampler2D motionVector;

layout(location = 0) rayPayloadEXT RayPayload Ray;//光线负载变量，用于在光线追踪过程中传递和存储光线与物体交点的信息
												  //例如交点的位置、颜色、法线等
												  //例如，如果一个光线击中了一个物体，最近命中着色器可能会计算出交点的颜色，
												  //并将这个颜色信息存入光线负载中。然后，在光线生成着色器（Ray Generation Shader）中，
												  //可以从光线负载中取出这个颜色信息，并使用它来更新像素的颜色。

void main() 
{
	//获取当前GPU时间以计算每个像素的渲染时间，生成热力图
	const uint64_t clock = Camera.ShowHeatmap ? clockARB() : 0;

	// Initialise separate random seeds for the pixel and the rays.
	// - pixel: we want the same random seed for each pixel to get a homogeneous anti-aliasing.
	// - ray: we want a noisy random seed, different for each pixel.
	//初始化像素的随机种子，产生一致的抗锯齿效果
	uint pixelRandomSeed = Camera.RandomSeed;
	//初始化每一条光线的随机种子，随机光线散射方向
	Ray.RandomSeed = InitRandomSeed(InitRandomSeed(gl_LaunchIDEXT.x, gl_LaunchIDEXT.y), Camera.TotalNumberOfSamples);

	//初始化像素颜色为黑色
	vec3 pixelColor = vec3(0);

	//1.1 读取上一帧的图像
    vec3 previousFrameColor = imageLoad(saveImage, ivec2(gl_LaunchIDEXT.xy)).rgb;

	// Accumulate all the rays for this pixels.
	//为每个像素发射SPP数量的光线
	for (uint s = 0; s < Camera.NumberOfSamples; ++s)
	{
		//if (Camera.NumberOfSamples != Camera.TotalNumberOfSamples) break;
		//在像素内部随机选择光线发射点，模拟抗锯齿效果
		const vec2 pixel = vec2(gl_LaunchIDEXT.x + RandomFloat(pixelRandomSeed), gl_LaunchIDEXT.y + RandomFloat(pixelRandomSeed));
		
		//将像素坐标转换到-1到1的均匀空间
		const vec2 uv = (pixel / gl_LaunchSizeEXT.xy) * 2.0 - 1.0;

		vec2 offset = Camera.Aperture/2 * RandomInUnitDisk(Ray.RandomSeed);//计算随机偏移量，模拟景深效果
		vec4 origin = Camera.ModelViewInverse * vec4(offset, 0, 1);//计算光线起点
		vec4 target = Camera.ProjectionInverse * (vec4(uv.x, uv.y, 1, 1));//转回裁剪坐标
		vec4 direction = Camera.ModelViewInverse * vec4(normalize(target.xyz * Camera.FocusDistance - vec3(offset, 0)), 0);//先转回世界空间坐标再计算光线方向
		vec3 rayColor = vec3(1);//初始化光线颜色为白色

		// Ray scatters are handled in this loop. There are no recursive traceRayEXT() calls in other shaders.
		//开始循环追踪计算光线的散射
		for (uint b = 0; b <= Camera.NumberOfBounces; ++b)
		{
			const float tMin = 0.001;
			const float tMax = 10000.0;

			// If we've exceeded the ray bounce limit without hitting a light source, no light is gathered.
			// Light emitting materials never scatter in this implementation, allowing us to make this logical shortcut.
			//当光线超过最大弹射次数仍然没有击中光源就停止，说明这里没有光照到并设置为黑色
			if (b == Camera.NumberOfBounces) 
			{
				rayColor = vec3(0, 0, 0);
				break;
			}

			//进行一次光线追踪操作，并填充下面的ColorAndDistance和ScatterDirection这两个变量
			//当这个函数调用时，如果光线与某一物体相交，就会调用相应的着色器并填充命中信息
			//这个函数只能在光线追踪的着色器类型中使用
			traceRayEXT(
				Scene, 
				gl_RayFlagsOpaqueEXT,//定义光线不透明，会被场景中的任何物体遮挡
				0xff, //用于过滤光线的交点，0xff表明所有可能的交点都会被考虑
				0 /*sbtRecordOffset*/, 0 /*sbtRecordStride*/, 0 /*missIndex*/, //着色器绑定表默认的着色器设置
				origin.xyz, tMin, direction.xyz, tMax,//光线起点、方向和光线可以达到的最大和最小的距离
				0 /*payload*/);
			
			const vec3 hitColor = Ray.ColorAndDistance.rgb;
			const float t = Ray.ColorAndDistance.w;
			const bool isScattered = Ray.ScatterDirection.w > 0;

			//更新光线颜色，每次光线在物体表面散射时光线颜色都会乘以物体的颜色
			rayColor *= hitColor;

			// Trace missed, or end of trace.
			//光线没有击中物体，或光线没有散射则退出追踪
			if (t < 0 || !isScattered)
			{				
				break;
			}

			// Trace hit.
			//如果光线击中物体并散射，则更新光线的起点和方向，进行下一次追踪
			origin = origin + t * direction;
			direction = vec4(Ray.ScatterDirection.xyz, 0);
		}

		//在结束一条光线的追踪后，把光线的颜色加到像素的颜色上
		pixelColor += rayColor;
	}

	//对光线颜色的累积值作平均处理
	const bool accumulate = Camera.NumberOfSamples != Camera.TotalNumberOfSamples;
	const vec3 accumulatedColor = (accumulate ? imageLoad(AccumulationImage, ivec2(gl_LaunchIDEXT.xy)) : vec4(0)).rgb + pixelColor;
	pixelColor = accumulatedColor / Camera.TotalNumberOfSamples;

	// Apply raytracing-in-one-weekend gamma correction.
	pixelColor = sqrt(pixelColor);

	//2.1从motion vector纹理中获取当前像素的motion：
	vec2 resolution = vec2(gl_LaunchSizeEXT.xy); // 获取屏幕分辨率
	vec2 currentMotion = texture(motionVector, vec2(gl_LaunchIDEXT.xy) / resolution).xy;

	//2.2使用计算出的motion vector获取上一帧中的对应像素颜色。
	vec3 previousFrameColorAtMovedPixel = imageLoad(saveImage, ivec2(gl_LaunchIDEXT.xy + currentMotion)).rgb;

	//2.3使用motion vector进行重投影
	//pixelColor = mix(pixelColor, previousFrameColorAtMovedPixel, 0.2);

	//1.2 结合当前帧与上一帧
	//pixelColor = mix(pixelColor, previousFrameColor, 0.5);  //这里是简单的平均，可以调整权重。

	if (Camera.ShowHeatmap)
	{
		const uint64_t deltaTime = clockARB() - clock;
		const float heatmapScale = 1000000.0f * Camera.HeatmapScale * Camera.HeatmapScale;
		const float deltaTimeScaled = clamp(float(deltaTime) / heatmapScale, 0.0f, 1.0f);
		
		pixelColor = heatmap(deltaTimeScaled);
	}

	//1.3 存储当前帧
    imageStore(saveImage, ivec2(gl_LaunchIDEXT.xy), vec4(pixelColor, 0));

	//这行代码是将累积颜色（accumulatedColor）存储到累积图像（AccumulationImage）中
	imageStore(AccumulationImage, ivec2(gl_LaunchIDEXT.xy), vec4(accumulatedColor, 0));
	//这行代码将像素颜色（pixelColor）存储到输出图像（OutputImage）中。
    imageStore(OutputImage, ivec2(gl_LaunchIDEXT.xy), vec4(pixelColor, 0));
}
